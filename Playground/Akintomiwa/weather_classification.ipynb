{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_**DELETE BEFORE PUBLISHING**_\n",
    "\n",
    "_This is a template also containing the style guide for use cases. The styling uses the use-case css when uploaded to the website, which will not be visible on your local machine._\n",
    "\n",
    "_Change any text marked with {} and delete any cells marked DELETE_\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       ".usecase-title, .usecase-duration, .usecase-section-header {\n",
       "    padding-left: 15px;\n",
       "    padding-bottom: 10px;\n",
       "    padding-top: 10px;\n",
       "    padding-right: 15px;\n",
       "    background-color: #0f9295;\n",
       "    color: #fff;\n",
       "}\n",
       "\n",
       ".usecase-title {\n",
       "    font-size: 1.7em;\n",
       "    font-weight: bold;\n",
       "}\n",
       "\n",
       ".usecase-authors, .usecase-level, .usecase-skill {\n",
       "    padding-left: 15px;\n",
       "    padding-bottom: 7px;\n",
       "    padding-top: 7px;\n",
       "    background-color: #baeaeb;\n",
       "    font-size: 1.4em;\n",
       "    color: #121212;\n",
       "}\n",
       "\n",
       ".usecase-level-skill  {\n",
       "    display: flex;\n",
       "}\n",
       "\n",
       ".usecase-level, .usecase-skill {\n",
       "    width: 50%;\n",
       "}\n",
       "\n",
       ".usecase-duration, .usecase-skill {\n",
       "    text-align: right;\n",
       "    padding-right: 15px;\n",
       "    padding-bottom: 8px;\n",
       "    font-size: 1.4em;\n",
       "}\n",
       "\n",
       ".usecase-section-header {\n",
       "    font-weight: bold;\n",
       "    font-size: 1.5em;\n",
       "}\n",
       "\n",
       ".usecase-subsection-header, .usecase-subsection-blurb {\n",
       "    font-weight: bold;\n",
       "    font-size: 1.2em;\n",
       "    color: #121212;\n",
       "}\n",
       "\n",
       ".usecase-subsection-blurb {\n",
       "    font-size: 1em;\n",
       "    font-style: italic;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DELETE BEFORE PUBLISHING\n",
    "# This is just here so you can preview the styling on your local machine\n",
    "\n",
    "from IPython.core.display import HTML\n",
    "HTML(\"\"\"\n",
    "<style>\n",
    ".usecase-title, .usecase-duration, .usecase-section-header {\n",
    "    padding-left: 15px;\n",
    "    padding-bottom: 10px;\n",
    "    padding-top: 10px;\n",
    "    padding-right: 15px;\n",
    "    background-color: #0f9295;\n",
    "    color: #fff;\n",
    "}\n",
    "\n",
    ".usecase-title {\n",
    "    font-size: 1.7em;\n",
    "    font-weight: bold;\n",
    "}\n",
    "\n",
    ".usecase-authors, .usecase-level, .usecase-skill {\n",
    "    padding-left: 15px;\n",
    "    padding-bottom: 7px;\n",
    "    padding-top: 7px;\n",
    "    background-color: #baeaeb;\n",
    "    font-size: 1.4em;\n",
    "    color: #121212;\n",
    "}\n",
    "\n",
    ".usecase-level-skill  {\n",
    "    display: flex;\n",
    "}\n",
    "\n",
    ".usecase-level, .usecase-skill {\n",
    "    width: 50%;\n",
    "}\n",
    "\n",
    ".usecase-duration, .usecase-skill {\n",
    "    text-align: right;\n",
    "    padding-right: 15px;\n",
    "    padding-bottom: 8px;\n",
    "    font-size: 1.4em;\n",
    "}\n",
    "\n",
    ".usecase-section-header {\n",
    "    font-weight: bold;\n",
    "    font-size: 1.5em;\n",
    "}\n",
    "\n",
    ".usecase-subsection-header, .usecase-subsection-blurb {\n",
    "    font-weight: bold;\n",
    "    font-size: 1.2em;\n",
    "    color: #121212;\n",
    "}\n",
    "\n",
    ".usecase-subsection-blurb {\n",
    "    font-size: 1em;\n",
    "    font-style: italic;\n",
    "}\n",
    "</style>\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"usecase-title\"><b>Weather Condition Classification</b></div>\n",
    "\n",
    "<div class=\"usecase-authors\"><b>Authored by: </b>Aremu Akintomiwa James</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"usecase-duration\"><b>Duration:</b> {90} mins</div>\n",
    "\n",
    "<div class=\"usecase-level-skill\">\n",
    "    <div class=\"usecase-level\"><b>Level: </b>{Intermediate}</div>\n",
    "    <div class=\"usecase-skill\"><b>Pre-requisite Skills: </b>Python, Data analysis, Machine Learning, Basic Meteorology</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"usecase-section-header\"><b>Scenario</b></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " As an urban planner or agricultural manager, I need to accurately classify different weather conditions using environmental features to determine the optimal times for infrastructure projects and agricultural activities. This will ensure that operations are conducted under favorable weather conditions, thereby providing actionable insights for planning and decision-making.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"usecase-section-header\"><b>What this use case will teach you</b></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the end of this use case you will:\n",
    "- Understand how to preprocess and analyze environmental data.\n",
    "- Learn how to build and evaluate a machine learning model for classification tasks.\n",
    "- Gain experience in feature selection and engineering for weather-related datasets.\n",
    "- Develop skills in using Python libraries such as Pandas, Scikit-learn, and Matplotlib.\n",
    "- Understand the importance of accurate weather classification for planning and decision-making in various sectors.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"usecase-section-header\"><b> introduction</b></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this use case, we aim to develop a robust machine learning model capable of accurately classifying various weather conditions such as sunny, cloudy, rainy, and stormy using environmental features. These features include ambient air temperature, relative humidity, atmospheric pressure, wind speed and direction, and gust wind speed. Accurate weather classification is important for optimizing the timing of infrastructure projects and agricultural activities, ensuring that operations are conducted under favorable weather conditions. By leveraging machine learning techniques, we can provide actionable insights for planning and decision-making.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"usecase-section-header\"><b>Background</b></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weather conditions have a significant impact on various sectors, including agriculture, construction, and transportation. Accurate weather forecasts and classifications can help in planning and executing operations more efficiently. For instance, farmers can optimize planting and harvesting times based on expected weather conditions, while construction projects can be scheduled to avoid adverse weather that could delay progress or compromise safety.\n",
    "\n",
    "In this project, we will use historical weather data from Melbourne's open data portal. The datasets include:\n",
    "- Microclimate sensors data — CoM Open Data Portal (melbourne.vic.gov.au)\n",
    "- Argyle Square Weather Stations (Historical Data) — CoM Open Data Portal (melbourne.vic.gov.au)\n",
    "\n",
    "- Argyle Square Air Quality — CoM Open Data Portal (melbourne.vic.gov.au)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"usecase-section-header\"><b>Dataset Information</b></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset for this project includes the following features::\n",
    "- Ambient air temperature (°C)\n",
    "- Relative humidity (%)\n",
    "- Atmospheric pressure (hPa)\n",
    "- Wind speed (m/s)\n",
    "- Wind direction (degrees)\n",
    "- Gust wind speed (m/s)\n",
    "\n",
    "\n",
    "These features will be used to classify weather conditions into categories such as sunny, cloudy, rainy, and stormy. The dataset will be preprocessed to handle any missing values, outliers, or inconsistencies before being used to train the machine learning model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dependencies\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd\n",
    "import requests\n",
    "from io import StringIO\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold, train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# **Preferred Method**: Export Endpoint\n",
    "\n",
    "\n",
    "def API_unlimited(datasetName):\n",
    "\n",
    "    dataset_id = datasetName\n",
    "    # https://data.melbourne.vic.gov.au/explore/dataset/pedestrian-counting-system-monthly-counts-per-hour/information/\n",
    "    #dataset_id = 'pedestrian-counting-system-monthly-counts-per-hour'\n",
    "    \n",
    "    base_url = 'https://data.melbourne.vic.gov.au/api/explore/v2.1/catalog/datasets/'\n",
    "    #apikey = api_key\n",
    "    dataset_id = dataset_id\n",
    "    format = 'csv'\n",
    "    \n",
    "    url = f'{base_url}{dataset_id}/exports/{format}'\n",
    "    params = {\n",
    "        'select': '*',\n",
    "        'limit': -1,  # all records\n",
    "        'lang': 'en',\n",
    "        'timezone': 'UTC',\n",
    "       # 'api_key': apikey\n",
    "    }\n",
    "    \n",
    "    # GET request\n",
    "    response = requests.get(url, params=params)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        # StringIO to read the CSV data\n",
    "        url_content = response.content.decode('utf-8')\n",
    "        datasetName = pd.read_csv(StringIO(url_content), delimiter=';')\n",
    "        print(datasetName.sample(10, random_state=999)) # Test\n",
    "        return datasetName\n",
    "    else:\n",
    "        print(f'Request failed with status code {response.status_code}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_id_1 = 'microclimate-sensors-data'\n",
    "dataset_id_2 = 'meshed-sensor-type-1'\n",
    "dataset_id_3 = 'argyle-square-air-quality'\n",
    "\n",
    "dataset1 = API_unlimited(dataset_id_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset2 = API_unlimited(dataset_id_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset3 = API_unlimited(dataset_id_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset3.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### standardizing column names for dataset1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset1 = dataset1.rename(columns={'received_at':'time', 'latlong':'lat_long', 'minimumwinddirection':'min_wind_direction', 'averagewinddirection':'avg_wind_direction', 'maximumwinddirection':'max_wind_direction', \n",
    "                        'minimumwindspeed':'min_wind_speed', 'averagewindspeed':'avg_wind_speed', 'gustwindspeed':'gust_wind_speed',\n",
    "          'airtemperature':'air_temp', 'relativehumidity':'humidity', 'atmosphericpressure':'atm_pressure'})\n",
    "dataset1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### atandersizing column names for datasets2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset2 =dataset2.rename(columns={'windspeed':'avg_wind_speed', 'winddirection':'avg_wind_direction', 'gustspeed':'gust_wind_speed',\n",
    "           'atmosphericpressure':'atm_pressure', 'relativehumidity':'humidity', 'airtemp':'air_temp'})\n",
    "dataset2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### standersizing column names for datasets3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset3.rename(columns={'temperature':'air_temp',})\n",
    "dataset3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset3.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### merging the datasets together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert time column in df1 to datetime with UTC timezone\n",
    "#dataset2['time'] = pd.to_datetime(dataset2['time'], utc=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_df = pd.concat([dataset2, dataset3], axis=1,join='inner')\n",
    "combine_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_percent =combine_df.isna().sum()*100/len(combine_df)\n",
    "missing_percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,3))\n",
    "new_par = missing_percent[missing_percent <= 10].plot.bar()\n",
    "plt.gca().set_xlabel(\"columns\")\n",
    "plt.gca().set_ylabel(\"counts\")\n",
    "plt.gca().set_title(\"percentage of missing value\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##column to work with\n",
    "selected_columns =['time', 'lat_long','rtc', 'battery', 'solarpanel', 'command', 'solar',\n",
    "       'precipitation', 'strikes', 'avg_wind_speed', 'avg_wind_direction',\n",
    "       'gust_wind_speed', 'vapourpressure', 'atm_pressure', 'humidity',\n",
    "       'air_temp', 'lat_long',   'averagespl', 'carbonmonoxide', 'humidity', 'ibatt',\n",
    "       'nitrogendioxide', 'ozone', 'particulateserr', 'particulatesvsn',\n",
    "       'peakspl', 'pm1', 'pm10', 'pm25', 'temperature', 'vbatt', 'vpanel']\n",
    "\n",
    "\n",
    "new_df = combine_df[selected_columns]\n",
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.columns = ['time_1', 'time_2', 'lat_long_1', 'lat_long_2', 'rtc', 'battery', 'solarpanel',\n",
    "       'command', 'solar', 'precipitation', 'strikes', 'avg_wind_speed',\n",
    "       'avg_wind_direction', 'gust_wind_speed', 'vapourpressure',\n",
    "       'atm_pressure', 'humidity', 'humidity', 'air_temp', 'lat_long',\n",
    "       'lat_long', 'averagespl', 'carbonmonoxide', 'humidity_1', 'humidity_2',\n",
    "       'ibatt', 'nitrogendioxide', 'ozone', 'particulateserr',\n",
    "       'particulatesvsn', 'peakspl', 'pm1', 'pm10', 'pm25', 'temperature',\n",
    "       'vbatt', 'vpanel']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df = new_df.drop(columns=['time_2','lat_long', 'lat_long_2','humidity','humidity_2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### checking the distribution of some features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#trying to check the distribution of \n",
    "plt.figure(figsize=(16,3))\n",
    "plt.subplot(1,3,1)\n",
    "cleaned_df['atm_pressure'].hist()\n",
    "plt.title('atm_pressure')\n",
    "plt.ylabel('counts')\n",
    "plt.xlabel('pressure level')\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "cleaned_df['ozone'].hist()\n",
    "plt.title('ozone')\n",
    "plt.ylabel('counts')\n",
    "plt.xlabel('ozone level')\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "cleaned_df['air_temp'].hist()\n",
    "plt.title('air_temp')\n",
    "plt.ylabel('counts')\n",
    "plt.xlabel('temp level')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####fillin up the nan with the their median\n",
    "for column in cleaned_df:\n",
    "    if pd.api.types.is_numeric_dtype(cleaned_df[column]):\n",
    "        cleaned_df[column].fillna(cleaned_df[column].median(), inplace=True)\n",
    "\n",
    "# Display the DataFrame after filling NA with median\n",
    "cleaned_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df.isna().sum()*100/len(cleaned_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cleaned_df['lat_long_1'] = cleaned_df['lat_long_1'].fillna(cleaned_df['lat_long_1'].mode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode_value = cleaned_df['lat_long_1'].mode()[0]\n",
    "\n",
    "cleaned_df['lat_long_1'] = cleaned_df['lat_long_1'].fillna(mode_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df.isna().sum()*100/len(cleaned_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ANalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variation od Avg_Wind_speed and Gust_Wind_speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Convert 'time_1' to datetime\n",
    "cleaned_df['time_1'] = pd.to_datetime(cleaned_df['time_1'])\n",
    "\n",
    "# Extract the month\n",
    "cleaned_df['month'] = cleaned_df['time_1'].dt.month\n",
    "\n",
    "# Calculate monthly means\n",
    "monthly_avg = cleaned_df.groupby('month')[['avg_wind_speed', 'gust_wind_speed']].mean()\n",
    "\n",
    "# Ensure all months are represented, even if some months might not have data\n",
    "all_months = pd.DataFrame({'month': np.arange(1, 13)})\n",
    "monthly_avg = all_months.merge(monthly_avg, on='month', how='left').set_index('month')\n",
    "\n",
    "# Set the background style to dark\n",
    "sns.set_style('darkgrid')\n",
    "plt.style.use('dark_background')\n",
    "\n",
    "# Plot monthly means\n",
    "plt.figure(figsize=(12, 5))\n",
    "ax = monthly_avg.plot(kind='line', marker='o', linestyle='-', ax=plt.gca(), color=['#1f77b4', '#ff7f0e'])\n",
    "plt.title('Seasonal Variation of Wind Speeds', fontsize=20, fontweight='bold', color='white')\n",
    "plt.xlabel('Month', fontsize=15, color='white')\n",
    "plt.ylabel('Wind Speed', fontsize=15, color='white')\n",
    "plt.xticks(ticks=np.arange(12), labels=['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'], color='white')\n",
    "plt.yticks(color='white')\n",
    "plt.legend(['Average Wind Speed', 'Gust Wind Speed'], fontsize=12)\n",
    "\n",
    "# Customize the plot appearance\n",
    "ax.spines['bottom'].set_color('white')\n",
    "ax.spines['left'].set_color('white')\n",
    "ax.tick_params(colors='white')\n",
    "ax.grid(True, linestyle='--', alpha=0.6)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The graph shows the seasonal variation of average wind speed and gust wind speed throughout the year. In February and September, both average and gust wind speeds peak, indicating stronger winds during these months. Conversely, December and October experience significant drops in wind speeds, with December starting low and October having a notable decline after the September peak.\n",
    "This  behavior during these periods may be due to changes seen in the winter and autumn months."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Impact of Vapour Pressure on Humidity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Set up the plotting area\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.style.use('dark_background')\n",
    "\n",
    "# Create scatter plot with a gradient based on density\n",
    "sns.scatterplot(x='vapourpressure', y='humidity_1', data=cleaned_df, hue='vapourpressure', palette='viridis')\n",
    "\n",
    "# Set plot title and labels\n",
    "plt.title('Impact of Vapour Pressure on Humidity Levels', color='white')\n",
    "plt.xlabel('Vapour Pressure', color='white')\n",
    "plt.ylabel('Humidity', color='white')\n",
    "plt.legend(title='Vapour Pressure', loc='upper right')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The scatter plot shows how vapour pressure and humidity levels are related, using different colors to represent various vapour pressure values. Higher vapour pressure, shown in green and yellow, usually goes along with higher humidity levels. Most data points fall between 1.0 and 2.5 vapour pressure units, with humidity levels ranging from 0% to 100%.\n",
    "\n",
    "When humidity levels are high (above 60%), vapour pressure values are spread out but tend to be higher. On the other hand, when humidity is low (below 40%), vapour pressure is generally lower, shown in purple and blue. This pattern suggests that higher humidity often means higher vapour pressure and more concentrated vapour pressure, though there is some variation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Patterns in Air Temperature, Humidity, and Pressure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "cleaned_df[['air_temp', 'humidity_1', 'atm_pressure']].plot()\n",
    "plt.title('Temporal Patterns in Air Temperature, Humidity, and Atmospheric Pressure')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Values')\n",
    "plt.legend(['Air Temperature', 'Humidity', 'Atmospheric Pressure'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The graph shows a moist environment as a result of the consistent high humidity levels.\n",
    "The air temperature, fluctuates a lot, suggesting regular cycles like daily or seasonal changes.\n",
    "The atmospheric pressure remains stable, which might indicate that significant weather changes might not be frequent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### patterns of pollutants across the year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(20, 9))\n",
    "plt.style.use('dark_background')\n",
    "\n",
    "months = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "\n",
    "# Plot for Carbon Monoxide\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.scatter(cleaned_df['month'], cleaned_df['carbonmonoxide'], color='cyan', alpha=0.5)\n",
    "plt.title('Carbon Monoxide Concentration by Month', color='white')\n",
    "plt.xlabel('Month', color='white')\n",
    "plt.ylabel('Carbon Monoxide (CO)', color='white')\n",
    "plt.xticks(range(1, 13), months, rotation=45, color='white')\n",
    "plt.yticks(color='white')\n",
    "\n",
    "# Plot for Nitrogen Dioxide\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.scatter(cleaned_df['month'], cleaned_df['nitrogendioxide'], color='magenta', alpha=0.5)\n",
    "plt.title('Nitrogen Dioxide Concentration by Month', color='white')\n",
    "plt.xlabel('Month', color='white')\n",
    "plt.ylabel('Nitrogen Dioxide (NO2)', color='white')\n",
    "plt.xticks(range(1, 13), months, rotation=45, color='white')\n",
    "plt.yticks(color='white')\n",
    "\n",
    "# Plot for PM10\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.scatter(cleaned_df['month'], cleaned_df['pm10'], color='yellow', alpha=0.5)\n",
    "plt.title('PM10 Concentration by Month', color='white')\n",
    "plt.xlabel('Month', color='white')\n",
    "plt.ylabel('PM10', color='white')\n",
    "plt.xticks(range(1, 13), months, rotation=45, color='white')\n",
    "plt.yticks(color='white')\n",
    "\n",
    "# Plot for PM2.5\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.scatter(cleaned_df['month'], cleaned_df['pm25'], color='lime', alpha=0.5)\n",
    "plt.title('PM2.5 Concentration by Month', color='white')\n",
    "plt.xlabel('Month', color='white')\n",
    "plt.ylabel('PM2.5', color='white')\n",
    "plt.xticks(range(1, 13), months, rotation=45, color='white')\n",
    "plt.yticks(color='white')\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carbon Monoxide (CO) and Nitrogen Dioxide (NO2):\n",
    "\n",
    "These pollutants have levels that go up and down every month, but there are no clear trends showing they are increasing or decreasing over time. This suggests that the sources of these pollutants, like cars and factories, are consistent throughout the year.\n",
    "\n",
    "PM10 and PM2.5:\n",
    "In terms pf PM10(particulate matter) levels also fluctuate each month without a clear trend, which might be due to weather changes or different activities.\n",
    "PM2.5(particulate matter) levels are stable and low throughout the year, indicating that efforts to control this pollutant might be effective."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Efect of pollutants across different years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 6))\n",
    "plt.scatter(cleaned_df.index, cleaned_df['ozone'], label='Ozone', color='#e377c2', alpha=0.6, s=10)\n",
    "plt.title('Ozone Levels Over Time', fontsize=20, fontweight='bold', color='white')\n",
    "plt.xlabel('Time', fontsize=15, color='white')\n",
    "plt.ylabel('Ozone Levels', fontsize=15, color='white')\n",
    "plt.xticks(color='white')\n",
    "plt.yticks(color='white')\n",
    "plt.legend(fontsize=12)\n",
    "plt.grid(True, linestyle='--', alpha=0.6)\n",
    "plt.style.use('dark_background')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The graph shows that ozone levels have been fairly consistent from 2021 to 2024, with most measurements densely clustered between 100 and 200 units. This indicates that the pollutant levels have remained stable over these years. The consistency in ozone levels suggests that the sources of pollution have not changed significantly.\n",
    "\n",
    "If this trend continues, it could have a lasting impact on air quality and health in the future. Monitoring and addressing these  pollutant levels are important to prevent negative effects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature engineering\n",
    "##### - removing the outlier\n",
    "##### - finding the correlation\n",
    "##### -getting the truth label for the dataset\n",
    "##### -normalizing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "outliers_dict = {}\n",
    "\n",
    "# Iterate through columns and process only numeric columns\n",
    "for column in cleaned_df.columns:\n",
    "    if pd.api.types.is_numeric_dtype(cleaned_df[column]):\n",
    "        # Calculate quantiles for the numeric column\n",
    "        Q1 = cleaned_df[column].quantile(0.25)\n",
    "        Q3 = cleaned_df[column].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        \n",
    "        # Identify outliers in the numeric column\n",
    "        outliers = ((cleaned_df[column] < (Q1 - 1.5 * IQR)) | (cleaned_df[column] > (Q3 + 1.5 * IQR))).sum()\n",
    "        \n",
    "        outliers_dict[column] = outliers\n",
    "print(outliers_dict)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import mstats\n",
    "# Define Winsorization limits\n",
    "lower_limit = 0.005\n",
    "upper_limit = 0.005\n",
    "\n",
    "# Apply Winsorization to the DataFrame\n",
    "cleaned_df_win = cleaned_df.copy()\n",
    "\n",
    "for column in cleaned_df.columns:\n",
    "    if column != 'time_1':  # Skip the datetime column\n",
    "        cleaned_df_win[column] = mstats.winsorize(cleaned_df[column], limits=(lower_limit, upper_limit))\n",
    "\n",
    "cleaned_df_win.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df_win.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df_win.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### getting the correlation of the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def corrheatmap(R, labels):\n",
    "    \"\"\"\n",
    "    Draws a correlation heat map, given:\n",
    "    * R - matrix of correlation coefficients for all variable pairs,\n",
    "    * labels - list of column names\n",
    "    \"\"\"\n",
    "    assert R.shape[0] == R.shape[1] and R.shape[0] == len(labels)\n",
    "    k = R.shape[0]\n",
    "\n",
    "    # plot the heat map using a custom colour palette\n",
    "    # (correlations are in [-1, 1])\n",
    "    plt.imshow(R, cmap=plt.get_cmap(\"RdBu\"), vmin=-1, vmax=1)\n",
    "\n",
    "    # add text labels\n",
    "    for i in range(k):\n",
    "        for j in range(k):\n",
    "            plt.text(j, i, f\"{R[i, j]:.2f}\", ha=\"center\", va=\"center\",\n",
    "                     color=\"black\" if np.abs(R[i, j]) < 0.5 else \"white\")\n",
    "\n",
    "    plt.xticks(np.arange(k), labels=labels, rotation=30, ha='right')\n",
    "    plt.tick_params(axis=\"x\", which=\"both\",\n",
    "                    labelbottom=True, labeltop=False, bottom=False, top=False)\n",
    "\n",
    "    plt.yticks(np.arange(k), labels=labels)\n",
    "    plt.tick_params(axis=\"y\", which=\"both\",\n",
    "                    labelleft=True, left=False, right=False)\n",
    "\n",
    "    plt.grid(False)\n",
    "    plt.colorbar()\n",
    "\n",
    "# Specify columns to exclude\n",
    "columns_to_exclude = ['time_1', 'lat_long_1', 'month', 'command', 'battery', 'peakspl',\n",
    "                     'ibatt', 'averagespl','rtc','solar','solarpanel']  # replace with your column names\n",
    "\n",
    "# Drop the specified columns\n",
    "cleaned_df_reduced = cleaned_df.drop(columns=columns_to_exclude)\n",
    "\n",
    "# Calculate the correlation matrix\n",
    "correlation_matrix = cleaned_df_reduced.corr()\n",
    "\n",
    "# Get the column labels\n",
    "labels = correlation_matrix.columns\n",
    "\n",
    "# Plot the correlation heatmap\n",
    "plt.figure(figsize=(15, 10))\n",
    "corrheatmap(correlation_matrix.values, labels)\n",
    "plt.title('Pearson Correlation Heatmap', fontsize=16, fontweight='bold')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### important columns needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df_win.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = cleaned_df_win[['time_1', 'lat_long_1', 'precipitation', 'strikes', 'avg_wind_speed',\n",
    "       'avg_wind_direction', 'gust_wind_speed', 'vapourpressure',\n",
    "       'atm_pressure', 'air_temp', 'carbonmonoxide',\n",
    "       'humidity_1', 'nitrogendioxide', 'ozone', 'particulateserr',\n",
    "       'particulatesvsn', 'pm1', 'pm10', 'pm25', 'temperature']]\n",
    "final_df['ozone'] = final_df['ozone'].apply(lambda x: max(x, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### creating a threshold for the Truth_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_weather(row):\n",
    "    # Define thresholds based on typical values for sunny weather\n",
    "    if (#row['atm_pressure'] > 101.2 and  # Above average atmospheric pressure\n",
    "        row['humidity_1'] < 40 and  # Lower humidity\n",
    "        row['temperature'] > 23):  # Higher temperature\n",
    "        return 'sunny'\n",
    "    \n",
    "    # Define thresholds for rainy weather\n",
    "    elif (#row['atm_pressure'] < 100.7 and  # Below average atmospheric pressure\n",
    "          row['humidity_1'] >= 70 and  # Higher humidity\n",
    "          row['temperature'] <= 21):  # Lower temperature\n",
    "        return 'rainy'\n",
    "    \n",
    "    # Define thresholds for cloudy weather\n",
    "    elif (#100.7 < row['atm_pressure'] < 101.2 and  # Intermediate atmospheric pressure\n",
    "          30 < row['humidity_1'] < 75 and  # Intermediate humidity\n",
    "          14 < row['temperature'] < 22):  # Intermediate temperature\n",
    "        return 'cloudy'\n",
    "    \n",
    "    # Define thresholds for stormy weather\n",
    "    elif (#row['atm_pressure'] < 100.0 and  # Very low atmospheric pressure\n",
    "          row['humidity_1'] > 85 and  # Very high humidity\n",
    "          row['temperature'] > 20):  # Variable temperature\n",
    "        return 'stormy'\n",
    "    \n",
    "    # Default case if no specific condition is met\n",
    "    return 'sunny'\n",
    "\n",
    "final_df['status'] = final_df.apply(classify_weather, axis=1)\n",
    "final_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['status'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting The percentage for each target label and visualizing it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_distribution = final_df['status'].value_counts()\n",
    "total_samples = final_df['status'].count()\n",
    "label_percentage = (label_distribution/total_samples)*100\n",
    "print(label_percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(8,3))\n",
    "final_df['status'].hist()\n",
    "plt.title(' The Weather Label',fontsize=16, fontweight='bold', color='white')\n",
    "plt.xlabel('target label', fontsize=12, color='white')\n",
    "plt.ylabel('counts', fontsize=12, color='white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalizing the dataset without the target label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Drop the non-numeric columns\n",
    "norm_column = final_df.iloc[:, 2:-1]\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "norm_column_scaled = scaler.fit_transform(norm_column)\n",
    "\n",
    "# Convert the normalized data back to a DataFrame with original column names\n",
    "norm_column_scaled = pd.DataFrame(norm_column_scaled, columns=norm_column.columns)\n",
    "\n",
    "norm_column_scaled.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "##########To be continued------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  features selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_column = final_df.iloc[:,0]\n",
    "last_column = final_df.iloc[:,-1]\n",
    "first_column.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combining my features needed for my model\n",
    "feat_df = pd.concat([first_column, norm_column_scaled, last_column], axis=1)\n",
    "feat_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### encoding my truth_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Select the last column\n",
    "last_column = feat_df.columns[-1]\n",
    "\n",
    "# Initialize LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Fit and transform the last column, and add the encoded values as a new column\n",
    "feat_df[last_column + '_encoded'] = label_encoder.fit_transform(feat_df[last_column])\n",
    "feat_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### using RandomForestRegressor to determine the features that contributed to high rate of Ozone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = feat_df.drop(columns=['time_1','status', 'ozone','status_encoded'])\n",
    "Y = feat_df['ozone']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size= 0.3, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "model = RandomForestRegressor(n_estimators = 100, random_state= 42)\n",
    "\n",
    "net = model.fit(X_train, Y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get features importance\n",
    "importance = model.feature_importances_\n",
    "feature_names = X.columns\n",
    "#Create a DataFrame for visualization\n",
    "importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': importance})\n",
    "importance_df = importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Plot feature importances\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.barh(importance_df['Feature'], importance_df['Importance'], color='skyblue')\n",
    "plt.xlabel('Importance', fontsize=15)\n",
    "plt.ylabel('Feature', fontsize=15)\n",
    "plt.title('Feature Importances for Ozone Levels', fontsize=20, fontweight='bold')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.style.use('dark_background')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The feature importance plot from the RandomForestRegressor shows that carbon monoxide and nitrogen dioxide are the biggest factors affecting ozone levels. Carbon monoxide has the highest impact, meaning it has a strong connection to ozone, likely because of its role in chemical reactions in the air. Nitrogen dioxide also significantly affects ozone, especially in places with heavy traffic emissions. Other factors like temperature have a smaller effect. This suggests that controlling carbon monoxide and nitrogen dioxide emissions is key to managing ozone levels effectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = feat_df.drop(columns=['time_1', 'status','status_encoded'])\n",
    "y = feat_df['status_encoded']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# Apply t-SNE\n",
    "#tsne = TSNE(n_components=2, random_state=42)\n",
    "#X_tsne = tsne.fit_transform(X_scaled)\n",
    "\n",
    "tsne = TSNE(n_components =2, random_state= 42)\n",
    "X_tsne = tsne.fit_transform(x)\n",
    "\n",
    "# Plotting the t-SNE results\n",
    "plt.figure(figsize=(8, 6))\n",
    "scatter = plt.scatter(X_tsne[:, 0], X_tsne[:, 1], c=y, cmap='viridis')\n",
    "\n",
    "# Adding a legend with labels\n",
    "unique_labels = list(feat_df['status_encoded'].unique())\n",
    "plt.legend(handles=scatter.legend_elements()[0], labels=unique_labels)\n",
    "plt.title('t-SNE Visualization of Iris Dataset')\n",
    "plt.xlabel('t-SNE Component 1')\n",
    "plt.ylabel('t-SNE Component 2')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".In this plot, we can see that the data points, represented by different colors for each class, are spread out and overlap in some areas rather than forming clear, separate clusters.This overlapping indicates that the data might not be easily separable using a simple linear boundary, suggesting that a non-linear model might be more effective for classification tasks on this dataset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Balancing the label using Resampling Technique by using combination of sampling called smote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = feat_df.drop(columns=['time_1', 'status','status_encoded'])\n",
    "y = feat_df['status_encoded']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#applying smote\n",
    "smote = SMOTE(random_state = 42)\n",
    "\n",
    "x_smote, y_smote = smote.fit_resample(x, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,3))\n",
    "y_smote.hist()\n",
    "plt.title(' The Weather Label',fontsize=16, fontweight='bold', color='white')\n",
    "plt.xlabel('target label', fontsize=12, color='white')\n",
    "plt.ylabel('counts', fontsize=12, color='white')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "This balanced distribution suggests that the dataset is now suitable for training machine learning models without being biased toward any particular weather condition. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### dataset splitting for model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split data for training\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_smote, y_smote, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### using a Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "\n",
    "#intialize logistic regresiom\n",
    "log_reg = LogisticRegression(penalty = 'l1', solver='liblinear', C=0.2)\n",
    "\n",
    "#cross_validation\n",
    "#cv = StratifiedKFold(n_splits =5, shuffle = True, random_state = 42)\n",
    "\n",
    "#perform cross val\n",
    "scores = cross_val_score(log_reg, x_train, y_train, cv=5, scoring='accuracy')\n",
    "\n",
    "#scores = cross_val_score(log_reg, x, y, cv=cv, scoring='accuracy')\n",
    "print(f'Cross-validated accuracy scores: {scores}')\n",
    "print(f'Average accuracy: {scores.mean():.2f}')\n",
    "\n",
    "log_reg.fit(x_train, y_train)\n",
    "\n",
    "#evaluation\n",
    "training_accuracy = log_reg.score(x_train,y_train)\n",
    "testing_accuracy = log_reg.score(x_test, y_test)\n",
    "\n",
    "print(f\"training_accuracy : {training_accuracy}\")\n",
    "print(f\"testing_accuracy : {testing_accuracy}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Cross-validated accuracy scores and mean accuracy for Logistic Regression\n",
    "scores_log_reg = [0.75065131, 0.74761187, 0.75005713, 0.74957722, 0.74898304]\n",
    "mean_accuracy_log_reg = np.mean(scores_log_reg)\n",
    "\n",
    "# Training and testing accuracy for Logistic Regression\n",
    "training_accuracy_log_reg = 0.7493029845971022\n",
    "testing_accuracy_log_reg = 0.7476690189769278\n",
    "\n",
    "# Plotting the accuracies for Logistic Regression without grid lines\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(range(1, 6), scores_log_reg, marker='o', linestyle='-', color='skyblue', label='Cross-validated Accuracy')\n",
    "plt.axhline(y=training_accuracy_log_reg, color='g', linestyle='-', label=f'Training Accuracy: {training_accuracy_log_reg:.2f}')\n",
    "plt.axhline(y=testing_accuracy_log_reg, color='b', linestyle='-', label=f'Testing Accuracy: {testing_accuracy_log_reg:.2f}')\n",
    "plt.title('Logistic Regression Classifier Accuracy')\n",
    "plt.xlabel('Fold')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='best')\n",
    "plt.grid(False)  # Disable grid lines\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_svm, x_test_svm, y_train_svm, y_test_svm= train_test_split(x_smote, y_smote, test_size=0.2, random_state=42)\n",
    "\n",
    "svm_clf = SVC(kernel = 'rbf', C= 0.2, gamma='scale', random_state = 42) #using rbf because is non-linear\n",
    "\n",
    "scores_svm = cross_val_score(svm_clf, x_train_svm, y_train_svm, cv=5, scoring= 'accuracy')\n",
    "print(f'Cross-validated accuracy scores: {scores_svm}')\n",
    "print(f'Average accuracy: {scores_svm.mean():.2f}')\n",
    "\n",
    "#fitting svm\n",
    "svm_clf.fit(x_train_svm, y_train_svm)\n",
    "\n",
    "training_accuracy_svm = svm_clf.score(x_train_svm,y_train_svm)\n",
    "testing_accuracy_svm = svm_clf.score(x_test_svm, y_test_svm)\n",
    "\n",
    "print(f\"training_accuracy : {training_accuracy_svm}\")\n",
    "print(f\"testing_accuracy : {testing_accuracy_svm}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validated accuracy scores and mean accuracy for SVM\n",
    "scores_svm = [0.94325609, 0.94321038, 0.94309612, 0.94122218, 0.94430733]\n",
    "mean_accuracy_svm = np.mean(scores_svm)\n",
    "\n",
    "# Training and testing accuracy for SVM\n",
    "training_accuracy_svm = 0.9478221125279949\n",
    "testing_accuracy_svm = 0.9467987860616476\n",
    "\n",
    "# Plotting the accuracies for SVM without grid lines\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(range(1, 6), scores_svm, marker='o', linestyle='-', color='skyblue', label='Cross-validated Accuracy')\n",
    "plt.axhline(y=training_accuracy_svm, color='g', linestyle='-', label=f'Training Accuracy: {training_accuracy_svm:.2f}')\n",
    "plt.axhline(y=testing_accuracy_svm, color='b', linestyle='-', label=f'Testing Accuracy: {testing_accuracy_svm:.2f}')\n",
    "plt.title('SVM Classifier Accuracy')\n",
    "plt.xlabel('Fold')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='best')\n",
    "plt.grid(False)  # Disable grid lines\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### using Decission Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_dt, x_test_dt, y_train_dt, y_test_dt= train_test_split(x_smote, y_smote, test_size=0.42,random_state=42)\n",
    "\n",
    "dt_clf = DecisionTreeClassifier(max_depth = 2, class_weight='balanced', criterion='gini',random_state=42)\n",
    "\n",
    "score_dt = cross_val_score(dt_clf, x_train_dt, y_train_dt, cv=5,scoring='accuracy')\n",
    "\n",
    "print(f'cross-validated accuracy scores: {score_dt}')\n",
    "print(f'Average accuracy: {score_dt.mean():.2f}')\n",
    "\n",
    "#fiiting decission tree\n",
    "dt_clf.fit(x_train_dt, y_train_dt)\n",
    "\n",
    "training_accuracy_dt = dt_clf.score(x_train_dt, y_train_dt)\n",
    "testing_accuracy_dt = dt_clf.score(x_test_dt, y_test_dt)\n",
    "\n",
    "print(f\"training_accuracy : {training_accuracy_dt}\")\n",
    "print(f\"testing_accuracy : {testing_accuracy_dt}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validated accuracy scores and mean accuracy for Decision Tree\n",
    "score_dt = [0.87703704, 0.87836091, 0.87675335, 0.87823099, 0.87823099]\n",
    "mean_accuracy_dt = np.mean(score_dt)\n",
    "\n",
    "# Training and testing accuracy for Decision Tree\n",
    "training_accuracy_dt = 0.8777289548173972\n",
    "testing_accuracy_dt = 0.8778740260305576\n",
    "\n",
    "# Plotting the accuracies for Decision Tree without grid lines\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(range(1, 6), score_dt, marker='o', linestyle='-', color='skyblue', label='Cross-validated Accuracy')\n",
    "plt.axhline(y=training_accuracy_dt, color='g', linestyle='-', label=f'Training Accuracy: {training_accuracy_dt:.2f}')\n",
    "plt.axhline(y=testing_accuracy_dt, color='b', linestyle='-', label=f'Testing Accuracy: {testing_accuracy_dt:.2f}')\n",
    "plt.title('Decision Tree Classifier Accuracy')\n",
    "plt.xlabel('Fold')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='best')\n",
    "plt.grid(False)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Cross-validated accuracy scores and mean accuracy for Decision Tree\n",
    "score_dt = [0.87703704, 0.87836091, 0.87675335, 0.87823099, 0.87823099]\n",
    "\n",
    "# Training and testing accuracy for Decision Tree\n",
    "training_accuracy_dt = 0.8777289548173972\n",
    "testing_accuracy_dt = 0.8778740260305576\n",
    "\n",
    "# Plotting the accuracies without grid lines and without the average line\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(range(1, 6), score_dt, marker='o', linestyle='-', color='skyblue', label='Cross-validated Accuracy')\n",
    "plt.axhline(y=training_accuracy_dt, color='g', linestyle='-', label=f'Training Accuracy: {training_accuracy_dt:.2f}')\n",
    "plt.axhline(y=testing_accuracy_dt, color='b', linestyle='-', label=f'Testing Accuracy: {testing_accuracy_dt:.2f}')\n",
    "plt.title('Decision Tree Classifier Accuracy')\n",
    "plt.xlabel('Fold')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='best')\n",
    "plt.grid(False)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_ad, x_test_ad, y_train_ad, y_test_ad= train_test_split(x_smote, y_smote, test_size=0.2, random_state=42)\n",
    "\n",
    "ad_clf = AdaBoostClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "score_ad = cross_val_score(ad_clf, x_train_ad, y_train_ad, cv=5, scoring='accuracy')\n",
    "\n",
    "\n",
    "print(f'cross-validated accuracy scores: {score_ad}')\n",
    "print(f'Average accuracy: {score_ad.mean():.2f}')\n",
    "\n",
    "ad_clf.fit(x_train, y_train)\n",
    "\n",
    "training_accuracy_ad = ad_clf.score(x_train_ad, y_train_ad)\n",
    "testing_accuracy_ad = ad_clf.score(x_test_ad, y_test_ad)\n",
    "\n",
    "print(f\"training_accuracy : {training_accuracy_ad}\")\n",
    "print(f\"testing_accuracy : {testing_accuracy_ad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Cross-validated accuracy scores and mean accuracy for AdaBoost\n",
    "score_ad = [0.83932081, 0.84425705, 0.84446273, 0.84473696, 0.84325152]\n",
    "mean_accuracy_ad = np.mean(score_ad)\n",
    "\n",
    "# Training and testing accuracy for AdaBoost\n",
    "training_accuracy_ad = 0.843973673385438\n",
    "testing_accuracy_ad = 0.8436505905151925\n",
    "\n",
    "# Plotting the accuracies for AdaBoost without grid lines\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(range(1, 6), score_ad, marker='o', linestyle='-', color='skyblue', label='Cross-validated Accuracy')\n",
    "plt.axhline(y=training_accuracy_ad, color='g', linestyle='-', label=f'Training Accuracy: {training_accuracy_ad:.2f}')\n",
    "plt.axhline(y=testing_accuracy_ad, color='b', linestyle='-', label=f'Testing Accuracy: {testing_accuracy_ad:.2f}')\n",
    "plt.title('AdaBoost Classifier Accuracy')\n",
    "plt.xlabel('Fold')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='best')\n",
    "plt.grid(False)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_rf, x_test_rf, y_train_rf, y_test_rf = train_test_split(x_smote, y_smote, test_size=0.2,random_state=42)\n",
    "\n",
    "rf_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "score_rf = cross_val_score(rf_clf,x_train_rf, y_train_rf, cv=5, scoring='accuracy')\n",
    "\n",
    "print(f'cross-validated accuracy score : {score_rf}')\n",
    "print(f'average accuracy : {score_rf.mean():.2f}')\n",
    "\n",
    "rf_clf.fit(x_train_rf,y_train_rf)\n",
    "\n",
    "training_accuracy_rf = rf_clf.score(x_train_rf, y_train_rf)\n",
    "testing_accuracy_rf = rf_clf.score(x_test_rf, y_test_rf)\n",
    "\n",
    "print(f\"training_accuracy : {training_accuracy_rf}\")\n",
    "print(f\"testing_accuracy : {testing_accuracy_rf}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Cross-validated accuracy scores and mean accuracy for RandomForest\n",
    "score_rf = [0.99933726, 0.99956579, 0.99949723, 0.99926871, 0.99954294]\n",
    "mean_accuracy_rf = np.mean(score_rf)\n",
    "\n",
    "# Training and testing accuracy for RandomForest\n",
    "training_accuracy_rf = 1.0\n",
    "testing_accuracy_rf = 0.9997997649414531 \n",
    "\n",
    "# Plotting the accuracies for RandomForest\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(range(1, 6), score_rf, marker='o', linestyle='-', label='Cross-validated Accuracy')\n",
    "#plt.axhline(y=mean_accuracy_rf, color='r', linestyle='--', label=f'Average CV Accuracy: {mean_accuracy_rf:.2f}')\n",
    "plt.axhline(y=training_accuracy_rf, color='g', linestyle='-', label=f'Training Accuracy: {training_accuracy_rf:.2f}')\n",
    "plt.axhline(y=testing_accuracy_rf, color='b', linestyle='-', label=f'Testing Accuracy: {testing_accuracy_rf:.2f}')\n",
    "plt.title('Random Forest Classifier Accuracy')\n",
    "plt.xlabel('Fold')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='best')\n",
    "plt.grid(False)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Comparing the performance of all models, the Random Forest classifier stands out as the best model for this classification task. It achieved the  highest cross-validated accuracy scores, averaging close to 1.00, and maintained perfect training accuracy (1.0) along with a nearly perfect testing accuracy (0.9998). These results suggest that the Random Forest model is extremely robust and effective at capturing the patterns in the data, significantly outperforming other models like SVM, Decision Tree, AdaBoost, and Logistic Regression in terms of both accuracy and consistency.\n",
    "##### However, the perfect or near-perfect scores also suggest that it might be overfitting slightly to the training data, but its high testing accuracy indicates it generalizes well to unseen data. This makes Random Forest the optimal choice among the evaluated models for its superior performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### predicting with random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "_**DELETE BEFORE PUBLISHING**_\n",
    "\n",
    "## Style guide for use cases\n",
    "\n",
    "### Headers\n",
    "\n",
    "For styling within your markdown cells, there are two choices you can use for headers.\n",
    "\n",
    "1) You can use HTML classes specific to the use case styling:\n",
    "\n",
    "```<p class=\"usecase-subsection-header\">This is a subsection header.</p>```\n",
    "\n",
    "<p style=\"font-weight: bold; font-size: 1.2em;\">This is a subsection header.</p>\n",
    "\n",
    "```<p class=\"usecase-subsection-blurb\">This is a blurb header.</p>```\n",
    "\n",
    "<p style=\"font-weight: bold; font-size: 1em; font-style:italic;\">This is a blurb header.</p>\n",
    "\n",
    "\n",
    "2) Or if you like you can use the markdown header styles:\n",
    "\n",
    "```# for h1```\n",
    "\n",
    "```## for h2```\n",
    "\n",
    "```### for h3```\n",
    "\n",
    "```#### for h4```\n",
    "\n",
    "```##### for h5```\n",
    "\n",
    "## Plot colour schemes\n",
    "\n",
    "General advice:\n",
    "1. Use the same colour or colour palette throughout your notebook, unless variety is necessary\n",
    "2. Select a palette based on the type of data being represented\n",
    "3. Consider accessibility (colourblindness, low vision)\n",
    "\n",
    "#### 1) If all of your plots only use 1-2 colors use one of the company style colors:\n",
    "\n",
    "| Light theme | Dark Theme |\n",
    "|-----|-----|\n",
    "|<p style=\"color:#2af598;\">#2af598</p>|<p style=\"color:#08af64;\">#08af64</p>|\n",
    "|<p style=\"color:#22e4ac;\">#22e4ac</p>|<p style=\"color:#14a38e;\">#14a38e</p>|\n",
    "|<p style=\"color:#1bd7bb;\">#1bd7bb</p>|<p style=\"color:#0f9295;\">#0f9295</p>|\n",
    "|<p style=\"color:#14c9cb;\">#14c9cb</p>|<p style=\"color:#056b8a;\">#056b8a</p>|\n",
    "|<p style=\"color:#0fbed8;\">#0fbed8</p>|<p style=\"color:#121212;\">#121212</p>|\n",
    "|<p style=\"color:#08b3e5;\">#08b3e5</p>||\n",
    "\n",
    "\n",
    "#### 2) If your plot needs multiple colors, choose an appropriate palette using either of the following tutorials:\n",
    "- https://seaborn.pydata.org/tutorial/color_palettes.html\n",
    "- https://matplotlib.org/stable/tutorials/colors/colormaps.html\n",
    "\n",
    "#### 3) Consider accessibility as well.\n",
    "\n",
    "For qualitative plotting Seaborn's 'colorblind' palette is recommended. For maps with sequential or diverging it is recommended to use one of the Color Brewer schemes which can be previewed at https://colorbrewer2.org/.\n",
    "\n",
    "If you want to design your own colour scheme, it should use the same principles as Cynthia Brewer's research (with variation not only in hue but also, saturation or luminance).\n",
    "\n",
    "### References\n",
    "\n",
    "Be sure to acknowledge your sources and any attributions using links or a reference list.\n",
    "\n",
    "If you have quite a few references, you might wish to have a dedicated section for references at the end of your document, linked using footnote style numbers.\n",
    "\n",
    "You can connect your in-text reference by adding the number with a HTML link: ```<a href=\"#fn-1\">[1]</a>```\n",
    "\n",
    "and add a matching ID in the reference list using the ```<fn>``` tag: ```<fn id=\"fn-1\">[1] Author (Year) _Title_, Publisher, Publication location.</fn>```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
